# KaliVibe ğŸ§ğŸ’»

**KaliVibe** is an autonomous security agent that runs natively on **Kali Linux**. It bridges Large Language Models with a persistent, stateful bash terminal using the **Model Context Protocol (MCP)**.

Think of it as an AI-powered sidekick for security professionals â€” one that remembers where it is, what it's done, and can execute real commands on your system.

---

## âœ¨ Features

- **ğŸ”„ Persistent Shell** â€” Unlike standard LLM tools, KaliVibe maintains state across commands. `cd` into a directory? You stay there.
- **ğŸ›¡ï¸ Safe File I/O** â€” Dedicated tools for reading and writing files, avoiding bash escaping nightmares.
- **ğŸ§¹ Sanitized Output** â€” Automatically strips ANSI escape codes and bracketed paste markers for clean LLM context.
- **âš¡ Timeout Protection** â€” Commands that hang (like `nc -lvnp`) are auto-interrupted after 30 seconds.
- **ğŸ”Œ MCP-Powered** â€” Uses the Model Context Protocol for standardized tool communication.

---

## ğŸš€ Quick Start

### Prerequisites

| Requirement | Version | Notes |
|-------------|---------|-------|
| Python | 3.13+ | Required |
| uv | Latest | Python package manager |
| OpenAI API Key | â€” | For LLM access |
| Node.js/npm | 18+ | Optional, for MCP Inspector debugging |

### Installation

```bash
# 1. Clone the repository
git clone https://github.com/AimanMadan/KaliVibe.git
cd KaliVibe

# 2. Configure your secrets
cp .env.example .env
# Edit .env with your OPENAI_API_KEY and preferred LLM_MODEL

# 3. Install dependencies
uv sync
```

### Running the Agent

```bash
uv run python -m src.main
```

You'll see:
```
Booting KaliVibe MCP Server...

[System]: Agent online using gpt-4o. Type 'exit' to quit.

User> _
```

---

## ğŸ— Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        KaliVibe                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    MCP Protocol    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚              â”‚ â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚                  â”‚  â”‚
â”‚   â”‚   OpenAI     â”‚                     â”‚   FastMCP        â”‚  â”‚
â”‚   â”‚   LLM Brain  â”‚                     â”‚   Server         â”‚  â”‚
â”‚   â”‚              â”‚ â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚                  â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    Tool Calls       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                  â”‚            â”‚
â”‚                                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚                                  â–¼               â–¼       â–¼    â”‚
â”‚                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”‚
â”‚                           â”‚ execute  â”‚  â”‚  read_   â”‚ â”‚writeâ”‚ â”‚
â”‚                           â”‚ command  â”‚  â”‚  file    â”‚ â”‚file â”‚ â”‚
â”‚                           â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                â”‚                             â”‚
â”‚                                â–¼                             â”‚
â”‚                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚                        â”‚   pexpect    â”‚                      â”‚
â”‚                        â”‚   BashSessionâ”‚                      â”‚
â”‚                        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚                                â”‚                             â”‚
â”‚                                â–¼                             â”‚
â”‚                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚                        â”‚  Kali Linux  â”‚                      â”‚
â”‚                        â”‚  Shell       â”‚                      â”‚
â”‚                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Project Structure

```
KaliVibe/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py              # Entry point
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ settings.py      # Centralized config & secrets
â”‚   â”œâ”€â”€ agent/
â”‚   â”‚   â””â”€â”€ llm.py           # OpenAI client + reasoning loop
â”‚   â”œâ”€â”€ mcp_server/
â”‚   â”‚   â””â”€â”€ server.py        # FastMCP tools (execute, read, write)
â”‚   â””â”€â”€ terminal/
â”‚       â””â”€â”€ session.py       # Persistent pexpect bash session
â”œâ”€â”€ .env.example             # Environment template
â”œâ”€â”€ pyproject.toml           # Project metadata & deps
â””â”€â”€ README.md
```

---

## ğŸ›  Available Tools

KaliVibe exposes three MCP tools to the LLM:

| Tool | Description |
|------|-------------|
| `execute_command` | Run any bash command in a persistent terminal |
| `read_file` | Safely read file contents (avoids `cat` issues) |
| `write_file` | Write content to files (avoids escaping issues) |

---

## âš™ï¸ Configuration

Edit `.env` to customize behavior:

```env
# Required
OPENAI_API_KEY=sk-your-api-key-here

# Optional (defaults shown)
LLM_MODEL=gpt-4o
```

### Supported Models

Any OpenAI-compatible model:
- `gpt-4o` (recommended)
- `gpt-4o-mini`
- `gpt-4-turbo`
- `o1-preview` / `o1-mini`

---

## ğŸ“– Usage Examples

### Basic Interaction

```
User> what's my current directory and what's here?

[KaliVibe]: Let me check that for you.
âš™ï¸  [Executing]: execute_command({'command': 'pwd && ls -la'})
ğŸ“„ [Result]:
/home/kali
total 32
drwxr-xr-x 4 kali kali 4096 Feb 26 10:00 .
drwxr-xr-x 3 root root 4096 Feb 25 09:00 ..
-rw-r--r-- 1 kali kali  220 Feb 25 09:00 .bash_logout
...

[KaliVibe]: You're in `/home/kali`. I can see the default home directory contents.
```

### Security Enumeration

```
User> check what ports are listening and what processes are running them

[KaliVibe]: I'll enumerate the listening ports and their associated processes.
âš™ï¸  [Executing]: execute_command({'command': 'ss -tlnp'})
...
```

### File Operations

```
User> create a simple nmap scan script in /tmp/

[KaliVibe]: I'll create that for you.
âš™ï¸  [Executing]: write_file({'filepath': '/tmp/scan.sh', 'content': '#!/bin/bash\n# Basic nmap scanner\ntarget=$1\nnmap -sV -sC $target\n'})
ğŸ“„ [Result]: Successfully wrote 89 characters to '/tmp/scan.sh'.

[KaliVibe]: Done! Make it executable with `chmod +x /tmp/scan.sh`.
```

---

## ğŸ”§ Development

### Setup Development Environment

```bash
# Install with dev dependencies
uv sync

# Run linting
uv run ruff check src/

# Format code
uv run ruff format src/
```

### Debugging with MCP Inspector

```bash
npx @modelcontextprotocol/inspector uv run python -m src.mcp_server.server
```

---

## âš ï¸ Security Considerations

**KaliVibe executes real commands on your system.** The LLM has full shell access.

- **Run in isolated environments** (VMs, containers) when possible
- **Review commands** before letting the agent run unattended
- **Never expose** the agent to untrusted inputs or networks
- **Audit logs** regularly if using in production

---

## ğŸ—º Roadmap

- [ ] Web dashboard for session monitoring
- [ ] Multi-terminal support
- [ ] Command logging & replay
- [ ] Restricted mode with command allowlists
- [ ] Integration with other LLM providers (Anthropic, local models)

---

## ğŸ¤ Contributing

Contributions are welcome! Please read our [Contributing Guide](docs/CONTRIBUTING.md) for details.

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- [Model Context Protocol](https://modelcontextprotocol.io/) - For the excellent tooling standard
- [OpenAI](https://openai.com/) - For the powerful LLM API
- [pexpect](https://pexpect.readthedocs.io/) - For robust terminal handling

---

<p align="center">
  <strong>Built with ğŸ’œ for the security community</strong>
</p>
